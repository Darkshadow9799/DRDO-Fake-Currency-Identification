{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nAuthor : Hritik Jain\\nDate   : 11/12/2016\\n\\nIn this script, I'll produce a Dataset with the single image of a Rs.500 currency note\\nand its fake version, which I simulated by erasing the watermark of Mahatma Gandhi with \\nan online image editor.\\nThe aim is to teach a CNN to differenciate between a fake and a real currency note.\\n_______________________________________________________________________________________\\n\\nI'm first going to try it out with the OpenCV library.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Author : Hritik Jain\n",
    "Date   : 11/12/2016\n",
    "\n",
    "In this script, I'll produce a Dataset with the single image of a Rs.500 currency note\n",
    "and its fake version, which I simulated by erasing the watermark of Mahatma Gandhi with \n",
    "an online image editor.\n",
    "The aim is to teach a CNN to differenciate between a fake and a real currency note.\n",
    "_______________________________________________________________________________________\n",
    "\n",
    "I'm first going to try it out with the OpenCV library.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking out the basic functionality\n",
    "\n",
    "img = cv2.imread('500 Testing/New Real 4/2.jpg')\n",
    "# converting to gray-scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (1000, 500), interpolation = cv2.INTER_AREA)\n",
    "cv2.namedWindow('img', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('img', img)\n",
    "# similarly, images can be written using the function imwrite and with the same arguments\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAssuming the image's name is passed as a command line argument,\\nhere's how we will get the image in a proper format to feed into \\nthe classifier, first resizing it to match the input layer size\\nwhich for now let's fix at 300 x 600, aspect ratio being 2:1\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assuming the image's name is passed as a command line argument,\n",
    "here's how we will get the image in a proper format to feed into \n",
    "the classifier, first resizing it to match the input layer size\n",
    "which for now let's fix at 300 x 600, aspect ratio being 2:1\n",
    "\"\"\"\n",
    "# wrap it into a function\n",
    "# import sys\n",
    "# img = cv2.imread(sys.arg[1])\n",
    "# img = cv2.resize(img,(1000, 500), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this will be the function used to resize and grayscale the the raw input image\n",
    "def resizeAndGray(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (600, 300), interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's produce the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for efficient memory storage :\n",
    "# since the numbers are between 0 and 255, numpy's int16 datatype can be used\n",
    "# secondly, we need to flatten the image array to store it efficiently ad row-major\n",
    "# so for that, we will numpy's use numpy's ravel function with 'copy' flag = False\n",
    "def generateDataForImages():\n",
    "    \"\"\"\n",
    "    In this function, various techniques for augementing image data, such as random rotations\n",
    "    and translations, zooming on images will performed to produce a dataset of size ~7000 images.\n",
    "    RETURN :\n",
    "        list of numpy arrays, one for each image\n",
    "    \"\"\"\n",
    "    \n",
    "    # this will be the function used to resize and grayscale the the raw input image\n",
    "    def resizeAndGray(img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (600, 300), interpolation = cv2.INTER_AREA)\n",
    "        return img\n",
    "    \n",
    "    trainingInput = []\n",
    "    noOfRows = 300\n",
    "    noOfCols = 600\n",
    "    \n",
    "    # first all real currency notes' images and then all the fake ones'\n",
    "    # i am skeptical of the consequences :-/\n",
    "    for directory in ['500 Testing/New Real 4/', '500 Testing/New Fake 4/']:\n",
    "        for filename in os.listdir(directory):\n",
    "            print filename\n",
    "            img = cv2.imread(directory + filename)\n",
    "            img = resizeAndGray(img)\n",
    "\n",
    "            # TRANSLATIONS\n",
    "            # will produce (10 + 10 + 1) x (10 + 10 + 1) = 441 images\n",
    "            # stride of 10 pixels along both axis along all 4 directions\n",
    "            for x in range(100, -110, -10):\n",
    "                for y in range(100, -110, -10):\n",
    "                    translationMatrix = np.float32([ [1,0,x], [0,1,y] ])\n",
    "                    imgTrns = cv2.warpAffine(img, translationMatrix, (noOfCols, noOfRows))\n",
    "                    trainingInput.append(np.ravel(imgTrns.astype(np.int16, copy = False)))\n",
    "\n",
    "\n",
    "            # ROTATIONS\n",
    "            # we produce 60 different angles in the range of -30 to 30\n",
    "            # with the step being equal to 0.5\n",
    "            for angle in range(30, -30, -1):\n",
    "                rotationMatrix = cv2.getRotationMatrix2D((noOfCols/2, noOfRows/2), float(angle)/2, 1)\n",
    "                imgRotated = cv2.warpAffine(img, rotationMatrix, (noOfCols, noOfRows))\n",
    "                trainingInput.append(np.ravel(imgRotated.astype(np.int16, copy = False)))\n",
    "\n",
    "            # PROJECTIVE TRANSFORMATIONS for ZOOMING IN AND ZOOMING OUT\n",
    "            # will produce (20 + 20) images for the dataset\n",
    "            # 1ST ZOOMING IN ...\n",
    "            for step in np.arange(0.005, 0.105, 0.005):\n",
    "                srcPoints = np.float32([[int(step*(noOfCols-1)),int(step*(noOfRows-1))], [int((1-step)*(noOfCols-1)),int(step*(noOfRows-1))], [int(step*(noOfCols-1)),int((1-step)*(noOfRows-1))], [int((1-step)*(noOfCols-1)), int((1-step)*(noOfRows-1))]])\n",
    "                dstPoints = np.float32([[0,0], [noOfCols-1,0], [0,noOfRows-1], [noOfCols-1,noOfRows-1]]) \n",
    "                projective_matrix = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "                imgZoomed = cv2.warpPerspective(img, projective_matrix, (noOfCols,noOfRows))\n",
    "                trainingInput.append(np.ravel(imgZoomed.astype(np.int16, copy = False)))\n",
    "            # 2ND ZOOMING OUT ...\n",
    "            for step in np.arange(0.005, 0.105, 0.005):\n",
    "                srcPoints = np.float32(np.float32([[0,0], [noOfCols-1,0], [0,noOfRows-1], [noOfCols-1,noOfRows-1]]))\n",
    "                dstPoints = np.float32([[int(step*(noOfCols-1)),int(step*(noOfRows-1))], [int((1-step)*(noOfCols-1)),int(step*(noOfRows-1))], [int(step*(noOfCols-1)),int((1-step)*(noOfRows-1))], [int((1-step)*(noOfCols-1)), int((1-step)*(noOfRows-1))]]) \n",
    "                projective_matrix = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "                imgZoomed = cv2.warpPerspective(img, projective_matrix, (noOfCols,noOfRows))\n",
    "                trainingInput.append(np.ravel(imgZoomed.astype(np.int16, copy = False)))\n",
    "\n",
    "    return trainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingInput = generateDataForImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingOutput = [1]*(len(trainingInput)/2) + [0]*(len(trainingInput)/2)\n",
    "dataset = (trainingInput, trainingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('trainingInput.pkl','wb') as fp:\n",
    "    cPickle.dump(dataset,fp, protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taking first 1000 images of both real and fake to see performance\n",
    "smallTrainingInput = trainingInput[1:1001] + trainingInput[7034:8034]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smallTrainingOutput = [1]*1000 + [0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mallDataset = (smallTrainingInput, smallTrainingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THIS FILE IS NOW MODIFIED AS PER THE CODE BELOW ! THIS WAS AN EARLY MISTAKE\n",
    "with open('smallFakeCurrencyDetectionData.pkl','wb') as fp:\n",
    "    cPickle.dump(smallDataset,fp, protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('smallFakeCurrencyDetectionData.pkl','rb') as fp:\n",
    "    trainData, validationData, testData = cPickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingInput = trainData[0][:900] + validationData[0][:50] + testData[0][:50] + trainData[0][900:] + validationData[0][50:] + testData[0][50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's updating the file smallFakeCurrencyDetectionData.pkl\n",
    "# just trying to make it compatible with Michael Nelson code's load_data_shared() function\n",
    "trainDataInput = []\n",
    "for i in xrange(0,900):\n",
    "    trainDataInput.append(trainingInput[i]) \n",
    "    trainDataInput.append(trainingInput[1000+i])\n",
    "\n",
    "validationDataInput = trainingInput[900:950] + trainingInput[1900:1950]\n",
    "testDataInput = trainingInput[950:1000] + trainingInput[1950:1999]\n",
    "\n",
    "trainDataOutput = []\n",
    "for i in xrange(900):\n",
    "    trainDataOutput += [1,0]\n",
    "    \n",
    "validationDataOutput = [1]*50 + [0]*50\n",
    "testDataOutput = [1]*50 + [0]*49\n",
    "\n",
    "trainData = (trainDataInput, trainDataOutput)\n",
    "validationData = (validationDataInput, validationDataOutput)\n",
    "testData = (testDataInput, testDataOutput)\n",
    "\n",
    "smallDataset = (trainData, validationData, testData)\n",
    "with open('smallFakeCurrencyDetectionData.pkl','wb') as fp:\n",
    "    cPickle.dump(smallDataset,fp, protocol = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
